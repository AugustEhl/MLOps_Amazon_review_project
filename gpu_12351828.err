Loaded module: cuda/10.2
wandb: Agent Starting Run: vd4lv1mg with config:
wandb: 	batch_size: 200
wandb: 	drop_out: 0.15
wandb: 	lr: 0.001
wandb: 	optimizer: sgd
wandb: Currently logged in as: augustehl (use `wandb login --relogin` to force relogin)
wandb: Tracking run with wandb version 0.12.9
wandb: Syncing run vivid-sweep-1
wandb: ⭐️ View project at https://wandb.ai/amazonproject/Amazon-Reviews
wandb: 🧹 View sweep at https://wandb.ai/amazonproject/Amazon-Reviews/sweeps/qr402qf2
wandb: 🚀 View run at https://wandb.ai/amazonproject/Amazon-Reviews/runs/vd4lv1mg
wandb: Run data is saved locally in /zhome/4a/f/117237/Documents/MLOps_Amazon_review_project/wandb/run-20220120_182808-vd4lv1mg
wandb: Run `wandb offline` to turn off syncing.
Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
wandb: Waiting for W&B process to finish, PID 222824... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:    (Batch accuracy) ▁▁▂▃▃▄▄▅▅▆▆▇▇█▁▂▂▃▄▄▅▅▆▆▇▇█▁▂▂▃▃▄▅▅▆▆▇▇█
wandb:        (Batch loss) ▁▁▂▃▃▄▄▅▅▆▆▇██▁▂▂▃▃▄▄▅▅▆▆▇▇▁▂▂▃▃▃▄▄▅▅▆▆▇
wandb:            Accuracy ▁▂█
wandb:                Loss █▃▁
wandb: 
wandb: Run summary:
wandb:    (Batch accuracy) 0.80359
wandb:        (Batch loss) 73.78381
wandb:            Accuracy 0.80359
wandb:                Loss 0.52703
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced vivid-sweep-1: https://wandb.ai/amazonproject/Amazon-Reviews/runs/vd4lv1mg
wandb: Find logs at: ./wandb/run-20220120_182808-vd4lv1mg/logs/debug.log
wandb: 
wandb: Agent Starting Run: u2q7yvz2 with config:
wandb: 	batch_size: 250
wandb: 	drop_out: 0.35
wandb: 	lr: 0.01
wandb: 	optimizer: sgd
wandb: Tracking run with wandb version 0.12.9
wandb: Syncing run quiet-sweep-2
wandb: ⭐️ View project at https://wandb.ai/amazonproject/Amazon-Reviews
wandb: 🧹 View sweep at https://wandb.ai/amazonproject/Amazon-Reviews/sweeps/qr402qf2
wandb: 🚀 View run at https://wandb.ai/amazonproject/Amazon-Reviews/runs/u2q7yvz2
wandb: Run data is saved locally in /zhome/4a/f/117237/Documents/MLOps_Amazon_review_project/wandb/run-20220120_183244-u2q7yvz2
wandb: Run `wandb offline` to turn off syncing.
Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
wandb: Waiting for W&B process to finish, PID 223116... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:    (Batch accuracy) ▁▁▂▂▃▃▄▄▅▆▆▇▇█▁▂▃▃▄▄▅▅▆▆▇▇█▁▂▂▃▃▄▅▅▆▆▇▇█
wandb:        (Batch loss) ▁▂▂▃▃▄▄▅▆▆▇▇██▁▁▂▃▃▄▄▄▅▅▆▆▇▁▁▂▂▃▃▄▄▄▅▅▅▆
wandb:            Accuracy ▁▅█
wandb:                Loss █▃▁
wandb: 
wandb: Run summary:
wandb:    (Batch accuracy) 0.82417
wandb:        (Batch loss) 51.72714
wandb:            Accuracy 0.82417
wandb:                Loss 0.46185
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced quiet-sweep-2: https://wandb.ai/amazonproject/Amazon-Reviews/runs/u2q7yvz2
wandb: Find logs at: ./wandb/run-20220120_183244-u2q7yvz2/logs/debug.log
wandb: 
wandb: Agent Starting Run: a9pvk8u4 with config:
wandb: 	batch_size: 250
wandb: 	drop_out: 0.35
wandb: 	lr: 0.01
wandb: 	optimizer: sgd
wandb: Tracking run with wandb version 0.12.9
wandb: Syncing run vivid-sweep-3
wandb: ⭐️ View project at https://wandb.ai/amazonproject/Amazon-Reviews
wandb: 🧹 View sweep at https://wandb.ai/amazonproject/Amazon-Reviews/sweeps/qr402qf2
wandb: 🚀 View run at https://wandb.ai/amazonproject/Amazon-Reviews/runs/a9pvk8u4
wandb: Run data is saved locally in /zhome/4a/f/117237/Documents/MLOps_Amazon_review_project/wandb/run-20220120_183700-a9pvk8u4
wandb: Run `wandb offline` to turn off syncing.
Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
wandb: Waiting for W&B process to finish, PID 223400... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:    (Batch accuracy) ▁▁▂▂▃▃▄▄▅▆▆▇▇█▁▂▃▃▄▄▅▅▆▆▇▇█▁▂▂▃▃▄▅▅▆▆▇▇█
wandb:        (Batch loss) ▁▂▂▃▃▄▄▅▆▆▇▇▇█▁▂▂▃▃▄▄▄▅▅▆▆▇▁▁▂▂▃▃▄▄▄▅▅▅▆
wandb:            Accuracy ▁▄█
wandb:                Loss █▃▁
wandb: 
wandb: Run summary:
wandb:    (Batch accuracy) 0.80513
wandb:        (Batch loss) 59.93791
wandb:            Accuracy 0.80513
wandb:                Loss 0.53516
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced vivid-sweep-3: https://wandb.ai/amazonproject/Amazon-Reviews/runs/a9pvk8u4
wandb: Find logs at: ./wandb/run-20220120_183700-a9pvk8u4/logs/debug.log
wandb: 
wandb: Agent Starting Run: v4xxk0hh with config:
wandb: 	batch_size: 250
wandb: 	drop_out: 0.25
wandb: 	lr: 0.001
wandb: 	optimizer: sgd
wandb: Tracking run with wandb version 0.12.9
wandb: Syncing run ancient-sweep-4
wandb: ⭐️ View project at https://wandb.ai/amazonproject/Amazon-Reviews
wandb: 🧹 View sweep at https://wandb.ai/amazonproject/Amazon-Reviews/sweeps/qr402qf2
wandb: 🚀 View run at https://wandb.ai/amazonproject/Amazon-Reviews/runs/v4xxk0hh
wandb: Run data is saved locally in /zhome/4a/f/117237/Documents/MLOps_Amazon_review_project/wandb/run-20220120_184112-v4xxk0hh
wandb: Run `wandb offline` to turn off syncing.
Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
wandb: Waiting for W&B process to finish, PID 223673... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:    (Batch accuracy) ▁▂▂▃▃▄▄▅▅▆▆▇▇█▁▂▃▃▄▄▅▅▆▆▇▇█▁▂▂▃▃▄▅▅▆▆▇▇█
wandb:        (Batch loss) ▁▂▂▃▃▄▄▅▆▆▇▇██▁▂▂▃▃▄▄▄▅▅▆▆▇▁▁▂▂▃▃▄▄▅▅▅▆▆
wandb:            Accuracy ▁▄█
wandb:                Loss █▃▁
wandb: 
wandb: Run summary:
wandb:    (Batch accuracy) 0.80184
wandb:        (Batch loss) 59.74936
wandb:            Accuracy 0.80184
wandb:                Loss 0.53348
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced ancient-sweep-4: https://wandb.ai/amazonproject/Amazon-Reviews/runs/v4xxk0hh
wandb: Find logs at: ./wandb/run-20220120_184112-v4xxk0hh/logs/debug.log
wandb: 
wandb: Agent Starting Run: jhtcx4io with config:
wandb: 	batch_size: 250
wandb: 	drop_out: 0.25
wandb: 	lr: 0.001
wandb: 	optimizer: adam
wandb: Tracking run with wandb version 0.12.9
wandb: Syncing run lunar-sweep-5
wandb: ⭐️ View project at https://wandb.ai/amazonproject/Amazon-Reviews
wandb: 🧹 View sweep at https://wandb.ai/amazonproject/Amazon-Reviews/sweeps/qr402qf2
wandb: 🚀 View run at https://wandb.ai/amazonproject/Amazon-Reviews/runs/jhtcx4io
wandb: Run data is saved locally in /zhome/4a/f/117237/Documents/MLOps_Amazon_review_project/wandb/run-20220120_184526-jhtcx4io
wandb: Run `wandb offline` to turn off syncing.
Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
wandb: Waiting for W&B process to finish, PID 223945... (success).
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:    (Batch accuracy) ▁▁▂▂▃▄▄▅▅▆▆▇▇█▁▂▃▃▄▄▅▅▆▆▇▇█▁▂▂▃▃▄▅▅▆▆▇▇█
wandb:        (Batch loss) ▁▂▂▃▃▄▄▅▆▆▆▇██▁▂▂▃▃▄▄▅▅▆▆▇▇▁▂▂▃▃▄▄▅▅▆▆▇▇
wandb:            Accuracy ▁██
wandb:                Loss █▂▁
wandb: 
wandb: Run summary:
wandb:    (Batch accuracy) 0.78917
wandb:        (Batch loss) 74.59134
wandb:            Accuracy 0.78917
wandb:                Loss 0.66599
wandb: 
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced lunar-sweep-5: https://wandb.ai/amazonproject/Amazon-Reviews/runs/jhtcx4io
wandb: Find logs at: ./wandb/run-20220120_184526-jhtcx4io/logs/debug.log
wandb: 
